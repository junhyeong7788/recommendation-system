{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d865645-6d86-4bda-9048-7908068fb48c",
   "metadata": {
    "id": "9d865645-6d86-4bda-9048-7908068fb48c"
   },
   "source": [
    "# MF를 이용한 추천시스템\n",
    "- 정확률 평가\n",
    "- 6-3의 셔플하는 것을 더 이해하는 것이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jGSSB5dmauAX",
   "metadata": {
    "id": "jGSSB5dmauAX"
   },
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2438df2-f047-4fe0-852c-01842ed2af5e",
   "metadata": {
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1728881756003,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "f2438df2-f047-4fe0-852c-01842ed2af5e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7290f6ac-eace-4280-be22-853b62315a78",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1728881756004,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "7290f6ac-eace-4280-be22-853b62315a78"
   },
   "outputs": [],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('/Users/jun/Library/Mobile Documents/com~apple~CloudDocs/Github/ai _recommendation _system/data/u.user', sep='|', names=u_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d79691c-28ce-4050-b499-17a6f7febc9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1728881756344,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "0d79691c-28ce-4050-b499-17a6f7febc9b",
    "outputId": "f8c47fab-8686-4791-a461-451f6d30f614"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release date</th>\n",
       "      <th>video release date</th>\n",
       "      <th>IMDB URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id              title release date  video release date  \\\n",
       "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            IMDB URL  unknown  Action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   Adventure  Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
       "0          0          1           1  ...        0          0       0        0   \n",
       "1          1          0           0  ...        0          0       0        0   \n",
       "2          0          0           0  ...        0          0       0        0   \n",
       "3          0          0           0  ...        0          0       0        0   \n",
       "4          0          0           0  ...        0          0       0        0   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0       0         0    0        0  \n",
       "1        0        0       0         1    0        0  \n",
       "2        0        0       0         1    0        0  \n",
       "3        0        0       0         0    0        0  \n",
       "4        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL', 'unknown',\n",
    "          'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary',\n",
    "          'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "          'Thriller', 'War', 'Western']\n",
    "movies = pd.read_csv('/Users/jun/Library/Mobile Documents/com~apple~CloudDocs/Github/ai _recommendation _system/data/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105c4c67-11da-44e4-8786-d675de322878",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1728881759278,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "105c4c67-11da-44e4-8786-d675de322878",
    "outputId": "8cf19c93-16b8-4829-b87f-a12a73a4c34e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0      196       242       3  881250949\n",
       "1      186       302       3  891717742\n",
       "2       22       377       1  878887116\n",
       "3      244        51       2  880606923\n",
       "4      166       346       1  886397596"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('/Users/jun/Library/Mobile Documents/com~apple~CloudDocs/Github/ai _recommendation _system/data/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ptNk7Z96-XIV",
   "metadata": {
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1728881773880,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "ptNk7Z96-XIV"
   },
   "outputs": [],
   "source": [
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3192643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating\n",
       "0          196       242       3\n",
       "1          186       302       3\n",
       "2           22       377       1\n",
       "3          244        51       2\n",
       "4          166       346       1\n",
       "...        ...       ...     ...\n",
       "99995      880       476       3\n",
       "99996      716       204       5\n",
       "99997      276      1090       1\n",
       "99998       13       225       2\n",
       "99999       12       203       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OUdF6KgJ7EtP",
   "metadata": {
    "id": "OUdF6KgJ7EtP"
   },
   "source": [
    "## train, test dataset 분리\n",
    "- 앞의 CF는 sklearn의 train_test_split을 사용하였는데, 여기서는 sklearn의 shuffle을 사용\n",
    "- `무작위 분할(shuffle)`\n",
    "    - 앞에서는 stratified sampling을 사용해서 각 사용자의 데이터 중 반드시 일부는 train set에 일부는 test set에 들어가도록 하였지만 여기서는 무작위이기 때문에 극단적인 경우 어떤 사용자의 모든 데이터가 train set이나 test set 한 곳에 다 들어갈 수도 있다.\n",
    "    - 특정 사용자에 대한 모든 데이터가 train set 또는 test set에 포함될 수 있는 단점이 존재,\n",
    "    - 이는 현실에서 발생할 수 있는 다양한 시나리오를 반영한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Cck0XX9T7KgF",
   "metadata": {
    "executionInfo": {
     "elapsed": 1364,
     "status": "ok",
     "timestamp": 1728881791690,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "Cck0XX9T7KgF"
   },
   "outputs": [],
   "source": [
    "# shuffle을 사용하여 train, test dataset에 고르게 배정되지 않을 수 있음\n",
    "from sklearn.utils import shuffle\n",
    "TRAIN_SIZE = 0.75 # test set 25% 비율로 지정\n",
    "\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings)) # 전체 데이터 중 Train_set의 비율에 해당하는 데이터가 몇 개인지 계산\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aTDbF7Zr1urS",
   "metadata": {
    "id": "aTDbF7Zr1urS"
   },
   "source": [
    "## MF Class\n",
    "- 사용자-아이템 평점 예측을 수행하는 클래스\n",
    "- **사용자-아이템 상호작용 행렬(R)** 을 기반으로 각 사용자와 아이템의 **잠재요인(latent factors)** 을 학습하고, 이를 통해 평점을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "NRkHlNYP1xjN",
   "metadata": {
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1728881969635,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "NRkHlNYP1xjN"
   },
   "outputs": [],
   "source": [
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings) # 사용자 - 아이템 평점 행렬 : Numpy 배열로 변환\n",
    "        \n",
    "##### >>>>> (2) user_id, item_id를 R의 index와 매핑하기 위한 dictionary 생성\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i]) # 아이디를 인덱스로 매핑해 주는 맵 item_id_index에 현재 아이템의 아이디와 인덱스를 저장\n",
    "            index_item_id.append([i, one_id]) # 반대로 인덱스를 아이디로 매핑해 주는 맵 index_item_id에 현재 아이템의 인덱스와 아이디를 저장\n",
    "        self.item_id_index = dict(item_id_index) # 아이템ID -> 인덱스\n",
    "        self.index_item_id = dict(index_item_id) # 인덱스 -> 아이템ID\n",
    "        \n",
    "        user_id_index = []                         # 위와 같은 작업을 사용자 아이디에 대해 실행\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index) # 사용자 ID -> 인덱스\n",
    "        self.index_user_id = dict(index_user_id) # 인덱스 -> 사용자 ID (원래대로 되돌림)\n",
    "        \n",
    "#### <<<<< (2)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set의 RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        \n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y) # 사용자-아이템 조합에 대해 예측 평점 계산\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        \n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    # 사용자 i 및 항목 j에 대한 ratings\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction) # 예측 오차 계산\n",
    "\n",
    "            # bias update\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            # latent factors matrix update\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "##### >>>>> (3)\n",
    "    # Test set을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        \n",
    "        for i in range(len(ratings_test)):      # test 데이터에 있는 각 데이터에 대해서\n",
    "            try:\n",
    "              x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "              y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "              z = ratings_test.iloc[i, 2]\n",
    "              test_set.append([x, y, z])\n",
    "              self.R[x, y] = 0                    # Setting test set ratings to 0\n",
    "            except:\n",
    "              print(i)\n",
    "        self.test_set = test_set\n",
    "        return test_set                         # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "    # Training 하면서 test set의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)) # 잠재요인 행렬 P와 Q를 랜덤 값으로 초기화\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            \n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "        return training_process\n",
    "\n",
    "    # 주어진 user_id 및 item_id에 대한 ratings 지정 / (특정 사용자와 아이템의 예측 평점을 반환)\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id]) \n",
    "\n",
    "    # Full user-movie rating matrix / (사용자-아이템 평점 행렬의 전체 예측 값을 반환)\n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7314549a",
   "metadata": {},
   "source": [
    "- 효율적인 데이터 처리\n",
    "    - ID를 바로 행렬에 사용할 경우, 매우 큰 차원을 가지는 희소 행렬이 생성될 수 있다.\n",
    "    - ID를 인덱스로 변환하면 행렬의 크기를 최소화할 수 있다.\n",
    "\n",
    "- **SGD(Stochastic Gradient Descent)**\n",
    "    - 사용자-아이템 평점 행렬을 분해하는 데 사용되는 최적화 알고리즘\n",
    "    - 전체 데이터를 반복적으로 학습하면서 최적의 파라미터를 찾는 방식\n",
    "    - 전체 데이터를 한 번 반복하는 것을 **에포크(epoch)** 라고 함\n",
    "    - 에포크가 끝날 때마다 전체 데이터에 대한 오차를 계산하고 이 오차를 최소화하는 방향으로 파라미터를 업데이트\n",
    "\n",
    "- Train RMSE와 Test RMSE를 각각 계산하는 이유\n",
    "    - 과적합이나 일반화 성능을 평가하기 위해 사용\n",
    "    1. Train RMSE\n",
    "        - 학습 데이터셋에 대해 모델이 얼마나 잘 예측하는지를 측정\n",
    "        - 이 값은 모델이 학습 데이터에서 얼마나 잘 학습했는지를 보여줌\n",
    "    2. Test RMSE\n",
    "        - 테스트 데이터셋에 대해 모델이 얼마나 잘 일반화 되는지를 측정\n",
    "        - 이 모델이 보지 못한 데이터(새로운 데이터)에서 얼마나 정확하게 예측할 수 있는 지를 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e42fb5-6c1c-476e-bcc4-bda93af7a426",
   "metadata": {
    "id": "92e42fb5-6c1c-476e-bcc4-bda93af7a426"
   },
   "source": [
    "# 최적의 K값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93ac8bd4-3410-4f90-8997-40199278331e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15677133,
     "status": "ok",
     "timestamp": 1728897651314,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "93ac8bd4-3410-4f90-8997-40199278331e",
    "outputId": "b80016b4-15df-4c3e-949f-80e5b860c87a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 50\n",
      "Iteration: 10 ; Train RMSE = 0.9661 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9414 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9305 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9241 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9197 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9164 ; Test RMSE = 0.9479\n",
      "Iteration: 70 ; Train RMSE = 0.9134 ; Test RMSE = 0.9466\n",
      "Iteration: 80 ; Train RMSE = 0.9104 ; Test RMSE = 0.9454\n",
      "Iteration: 90 ; Train RMSE = 0.9068 ; Test RMSE = 0.9443\n",
      "Iteration: 100 ; Train RMSE = 0.9023 ; Test RMSE = 0.9428\n",
      "Iteration: 110 ; Train RMSE = 0.8961 ; Test RMSE = 0.9409\n",
      "Iteration: 120 ; Train RMSE = 0.8878 ; Test RMSE = 0.9384\n",
      "Iteration: 130 ; Train RMSE = 0.8770 ; Test RMSE = 0.9352\n",
      "Iteration: 140 ; Train RMSE = 0.8638 ; Test RMSE = 0.9316\n",
      "Iteration: 150 ; Train RMSE = 0.8487 ; Test RMSE = 0.9281\n",
      "Iteration: 160 ; Train RMSE = 0.8320 ; Test RMSE = 0.9249\n",
      "Iteration: 170 ; Train RMSE = 0.8139 ; Test RMSE = 0.9223\n",
      "Iteration: 180 ; Train RMSE = 0.7945 ; Test RMSE = 0.9202\n",
      "Iteration: 190 ; Train RMSE = 0.7740 ; Test RMSE = 0.9188\n",
      "Iteration: 200 ; Train RMSE = 0.7527 ; Test RMSE = 0.9182\n",
      "Iteration: 210 ; Train RMSE = 0.7311 ; Test RMSE = 0.9182\n",
      "Iteration: 220 ; Train RMSE = 0.7093 ; Test RMSE = 0.9190\n",
      "Iteration: 230 ; Train RMSE = 0.6878 ; Test RMSE = 0.9204\n",
      "Iteration: 240 ; Train RMSE = 0.6666 ; Test RMSE = 0.9223\n",
      "Iteration: 250 ; Train RMSE = 0.6460 ; Test RMSE = 0.9246\n",
      "Iteration: 260 ; Train RMSE = 0.6262 ; Test RMSE = 0.9273\n",
      "Iteration: 270 ; Train RMSE = 0.6071 ; Test RMSE = 0.9302\n",
      "Iteration: 280 ; Train RMSE = 0.5889 ; Test RMSE = 0.9332\n",
      "Iteration: 290 ; Train RMSE = 0.5715 ; Test RMSE = 0.9364\n",
      "Iteration: 300 ; Train RMSE = 0.5551 ; Test RMSE = 0.9395\n",
      "K = 60\n",
      "Iteration: 10 ; Train RMSE = 0.9662 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9415 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9307 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9243 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9201 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9168 ; Test RMSE = 0.9479\n",
      "Iteration: 70 ; Train RMSE = 0.9140 ; Test RMSE = 0.9466\n",
      "Iteration: 80 ; Train RMSE = 0.9112 ; Test RMSE = 0.9454\n",
      "Iteration: 90 ; Train RMSE = 0.9079 ; Test RMSE = 0.9443\n",
      "Iteration: 100 ; Train RMSE = 0.9037 ; Test RMSE = 0.9429\n",
      "Iteration: 110 ; Train RMSE = 0.8980 ; Test RMSE = 0.9410\n",
      "Iteration: 120 ; Train RMSE = 0.8903 ; Test RMSE = 0.9385\n",
      "Iteration: 130 ; Train RMSE = 0.8802 ; Test RMSE = 0.9354\n",
      "Iteration: 140 ; Train RMSE = 0.8680 ; Test RMSE = 0.9319\n",
      "Iteration: 150 ; Train RMSE = 0.8539 ; Test RMSE = 0.9285\n",
      "Iteration: 160 ; Train RMSE = 0.8382 ; Test RMSE = 0.9254\n",
      "Iteration: 170 ; Train RMSE = 0.8210 ; Test RMSE = 0.9227\n",
      "Iteration: 180 ; Train RMSE = 0.8021 ; Test RMSE = 0.9205\n",
      "Iteration: 190 ; Train RMSE = 0.7819 ; Test RMSE = 0.9188\n",
      "Iteration: 200 ; Train RMSE = 0.7604 ; Test RMSE = 0.9178\n",
      "Iteration: 210 ; Train RMSE = 0.7381 ; Test RMSE = 0.9174\n",
      "Iteration: 220 ; Train RMSE = 0.7153 ; Test RMSE = 0.9178\n",
      "Iteration: 230 ; Train RMSE = 0.6923 ; Test RMSE = 0.9189\n",
      "Iteration: 240 ; Train RMSE = 0.6695 ; Test RMSE = 0.9205\n",
      "Iteration: 250 ; Train RMSE = 0.6471 ; Test RMSE = 0.9227\n",
      "Iteration: 260 ; Train RMSE = 0.6254 ; Test RMSE = 0.9253\n",
      "Iteration: 270 ; Train RMSE = 0.6044 ; Test RMSE = 0.9281\n",
      "Iteration: 280 ; Train RMSE = 0.5844 ; Test RMSE = 0.9312\n",
      "Iteration: 290 ; Train RMSE = 0.5653 ; Test RMSE = 0.9344\n",
      "Iteration: 300 ; Train RMSE = 0.5471 ; Test RMSE = 0.9377\n",
      "K = 70\n",
      "Iteration: 10 ; Train RMSE = 0.9662 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9416 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9308 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9245 ; Test RMSE = 0.9524\n",
      "Iteration: 50 ; Train RMSE = 0.9203 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9172 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9145 ; Test RMSE = 0.9467\n",
      "Iteration: 80 ; Train RMSE = 0.9119 ; Test RMSE = 0.9456\n",
      "Iteration: 90 ; Train RMSE = 0.9091 ; Test RMSE = 0.9446\n",
      "Iteration: 100 ; Train RMSE = 0.9054 ; Test RMSE = 0.9435\n",
      "Iteration: 110 ; Train RMSE = 0.9006 ; Test RMSE = 0.9420\n",
      "Iteration: 120 ; Train RMSE = 0.8939 ; Test RMSE = 0.9399\n",
      "Iteration: 130 ; Train RMSE = 0.8848 ; Test RMSE = 0.9370\n",
      "Iteration: 140 ; Train RMSE = 0.8732 ; Test RMSE = 0.9335\n",
      "Iteration: 150 ; Train RMSE = 0.8592 ; Test RMSE = 0.9298\n",
      "Iteration: 160 ; Train RMSE = 0.8434 ; Test RMSE = 0.9261\n",
      "Iteration: 170 ; Train RMSE = 0.8259 ; Test RMSE = 0.9228\n",
      "Iteration: 180 ; Train RMSE = 0.8069 ; Test RMSE = 0.9199\n",
      "Iteration: 190 ; Train RMSE = 0.7866 ; Test RMSE = 0.9177\n",
      "Iteration: 200 ; Train RMSE = 0.7652 ; Test RMSE = 0.9161\n",
      "Iteration: 210 ; Train RMSE = 0.7431 ; Test RMSE = 0.9152\n",
      "Iteration: 220 ; Train RMSE = 0.7205 ; Test RMSE = 0.9150\n",
      "Iteration: 230 ; Train RMSE = 0.6977 ; Test RMSE = 0.9154\n",
      "Iteration: 240 ; Train RMSE = 0.6749 ; Test RMSE = 0.9164\n",
      "Iteration: 250 ; Train RMSE = 0.6524 ; Test RMSE = 0.9179\n",
      "Iteration: 260 ; Train RMSE = 0.6304 ; Test RMSE = 0.9198\n",
      "Iteration: 270 ; Train RMSE = 0.6089 ; Test RMSE = 0.9220\n",
      "Iteration: 280 ; Train RMSE = 0.5881 ; Test RMSE = 0.9244\n",
      "Iteration: 290 ; Train RMSE = 0.5681 ; Test RMSE = 0.9270\n",
      "Iteration: 300 ; Train RMSE = 0.5489 ; Test RMSE = 0.9297\n",
      "K = 80\n",
      "Iteration: 10 ; Train RMSE = 0.9662 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9417 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9309 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9246 ; Test RMSE = 0.9524\n",
      "Iteration: 50 ; Train RMSE = 0.9205 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9174 ; Test RMSE = 0.9479\n",
      "Iteration: 70 ; Train RMSE = 0.9148 ; Test RMSE = 0.9466\n",
      "Iteration: 80 ; Train RMSE = 0.9123 ; Test RMSE = 0.9456\n",
      "Iteration: 90 ; Train RMSE = 0.9095 ; Test RMSE = 0.9446\n",
      "Iteration: 100 ; Train RMSE = 0.9060 ; Test RMSE = 0.9434\n",
      "Iteration: 110 ; Train RMSE = 0.9013 ; Test RMSE = 0.9418\n",
      "Iteration: 120 ; Train RMSE = 0.8948 ; Test RMSE = 0.9396\n",
      "Iteration: 130 ; Train RMSE = 0.8860 ; Test RMSE = 0.9367\n",
      "Iteration: 140 ; Train RMSE = 0.8749 ; Test RMSE = 0.9332\n",
      "Iteration: 150 ; Train RMSE = 0.8619 ; Test RMSE = 0.9296\n",
      "Iteration: 160 ; Train RMSE = 0.8473 ; Test RMSE = 0.9262\n",
      "Iteration: 170 ; Train RMSE = 0.8311 ; Test RMSE = 0.9230\n",
      "Iteration: 180 ; Train RMSE = 0.8134 ; Test RMSE = 0.9202\n",
      "Iteration: 190 ; Train RMSE = 0.7940 ; Test RMSE = 0.9179\n",
      "Iteration: 200 ; Train RMSE = 0.7732 ; Test RMSE = 0.9161\n",
      "Iteration: 210 ; Train RMSE = 0.7512 ; Test RMSE = 0.9149\n",
      "Iteration: 220 ; Train RMSE = 0.7283 ; Test RMSE = 0.9144\n",
      "Iteration: 230 ; Train RMSE = 0.7050 ; Test RMSE = 0.9146\n",
      "Iteration: 240 ; Train RMSE = 0.6816 ; Test RMSE = 0.9154\n",
      "Iteration: 250 ; Train RMSE = 0.6583 ; Test RMSE = 0.9167\n",
      "Iteration: 260 ; Train RMSE = 0.6354 ; Test RMSE = 0.9184\n",
      "Iteration: 270 ; Train RMSE = 0.6130 ; Test RMSE = 0.9205\n",
      "Iteration: 280 ; Train RMSE = 0.5913 ; Test RMSE = 0.9229\n",
      "Iteration: 290 ; Train RMSE = 0.5703 ; Test RMSE = 0.9254\n",
      "Iteration: 300 ; Train RMSE = 0.5502 ; Test RMSE = 0.9281\n",
      "K = 90\n",
      "Iteration: 10 ; Train RMSE = 0.9663 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9418 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9310 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9248 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9207 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9177 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9153 ; Test RMSE = 0.9467\n",
      "Iteration: 80 ; Train RMSE = 0.9130 ; Test RMSE = 0.9457\n",
      "Iteration: 90 ; Train RMSE = 0.9105 ; Test RMSE = 0.9447\n",
      "Iteration: 100 ; Train RMSE = 0.9076 ; Test RMSE = 0.9437\n",
      "Iteration: 110 ; Train RMSE = 0.9036 ; Test RMSE = 0.9423\n",
      "Iteration: 120 ; Train RMSE = 0.8981 ; Test RMSE = 0.9404\n",
      "Iteration: 130 ; Train RMSE = 0.8904 ; Test RMSE = 0.9377\n",
      "Iteration: 140 ; Train RMSE = 0.8803 ; Test RMSE = 0.9343\n",
      "Iteration: 150 ; Train RMSE = 0.8678 ; Test RMSE = 0.9304\n",
      "Iteration: 160 ; Train RMSE = 0.8533 ; Test RMSE = 0.9264\n",
      "Iteration: 170 ; Train RMSE = 0.8374 ; Test RMSE = 0.9228\n",
      "Iteration: 180 ; Train RMSE = 0.8200 ; Test RMSE = 0.9195\n",
      "Iteration: 190 ; Train RMSE = 0.8011 ; Test RMSE = 0.9168\n",
      "Iteration: 200 ; Train RMSE = 0.7807 ; Test RMSE = 0.9146\n",
      "Iteration: 210 ; Train RMSE = 0.7591 ; Test RMSE = 0.9131\n",
      "Iteration: 220 ; Train RMSE = 0.7365 ; Test RMSE = 0.9122\n",
      "Iteration: 230 ; Train RMSE = 0.7133 ; Test RMSE = 0.9120\n",
      "Iteration: 240 ; Train RMSE = 0.6897 ; Test RMSE = 0.9124\n",
      "Iteration: 250 ; Train RMSE = 0.6661 ; Test RMSE = 0.9134\n",
      "Iteration: 260 ; Train RMSE = 0.6427 ; Test RMSE = 0.9149\n",
      "Iteration: 270 ; Train RMSE = 0.6198 ; Test RMSE = 0.9168\n",
      "Iteration: 280 ; Train RMSE = 0.5975 ; Test RMSE = 0.9190\n",
      "Iteration: 290 ; Train RMSE = 0.5759 ; Test RMSE = 0.9214\n",
      "Iteration: 300 ; Train RMSE = 0.5550 ; Test RMSE = 0.9239\n",
      "K = 100\n",
      "Iteration: 10 ; Train RMSE = 0.9663 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9418 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9310 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9249 ; Test RMSE = 0.9524\n",
      "Iteration: 50 ; Train RMSE = 0.9208 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9178 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9154 ; Test RMSE = 0.9467\n",
      "Iteration: 80 ; Train RMSE = 0.9132 ; Test RMSE = 0.9457\n",
      "Iteration: 90 ; Train RMSE = 0.9108 ; Test RMSE = 0.9448\n",
      "Iteration: 100 ; Train RMSE = 0.9079 ; Test RMSE = 0.9437\n",
      "Iteration: 110 ; Train RMSE = 0.9040 ; Test RMSE = 0.9424\n",
      "Iteration: 120 ; Train RMSE = 0.8986 ; Test RMSE = 0.9405\n",
      "Iteration: 130 ; Train RMSE = 0.8911 ; Test RMSE = 0.9379\n",
      "Iteration: 140 ; Train RMSE = 0.8814 ; Test RMSE = 0.9346\n",
      "Iteration: 150 ; Train RMSE = 0.8696 ; Test RMSE = 0.9309\n",
      "Iteration: 160 ; Train RMSE = 0.8560 ; Test RMSE = 0.9273\n",
      "Iteration: 170 ; Train RMSE = 0.8409 ; Test RMSE = 0.9239\n",
      "Iteration: 180 ; Train RMSE = 0.8243 ; Test RMSE = 0.9208\n",
      "Iteration: 190 ; Train RMSE = 0.8059 ; Test RMSE = 0.9181\n",
      "Iteration: 200 ; Train RMSE = 0.7859 ; Test RMSE = 0.9159\n",
      "Iteration: 210 ; Train RMSE = 0.7645 ; Test RMSE = 0.9141\n",
      "Iteration: 220 ; Train RMSE = 0.7420 ; Test RMSE = 0.9130\n",
      "Iteration: 230 ; Train RMSE = 0.7186 ; Test RMSE = 0.9125\n",
      "Iteration: 240 ; Train RMSE = 0.6947 ; Test RMSE = 0.9127\n",
      "Iteration: 250 ; Train RMSE = 0.6707 ; Test RMSE = 0.9134\n",
      "Iteration: 260 ; Train RMSE = 0.6469 ; Test RMSE = 0.9146\n",
      "Iteration: 270 ; Train RMSE = 0.6234 ; Test RMSE = 0.9162\n",
      "Iteration: 280 ; Train RMSE = 0.6005 ; Test RMSE = 0.9182\n",
      "Iteration: 290 ; Train RMSE = 0.5783 ; Test RMSE = 0.9203\n",
      "Iteration: 300 ; Train RMSE = 0.5569 ; Test RMSE = 0.9226\n",
      "K = 110\n",
      "Iteration: 10 ; Train RMSE = 0.9663 ; Test RMSE = 0.9833\n",
      "Iteration: 20 ; Train RMSE = 0.9418 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9311 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9249 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9209 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9180 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9156 ; Test RMSE = 0.9467\n",
      "Iteration: 80 ; Train RMSE = 0.9134 ; Test RMSE = 0.9457\n",
      "Iteration: 90 ; Train RMSE = 0.9111 ; Test RMSE = 0.9448\n",
      "Iteration: 100 ; Train RMSE = 0.9083 ; Test RMSE = 0.9438\n",
      "Iteration: 110 ; Train RMSE = 0.9046 ; Test RMSE = 0.9425\n",
      "Iteration: 120 ; Train RMSE = 0.8995 ; Test RMSE = 0.9406\n",
      "Iteration: 130 ; Train RMSE = 0.8924 ; Test RMSE = 0.9381\n",
      "Iteration: 140 ; Train RMSE = 0.8830 ; Test RMSE = 0.9349\n",
      "Iteration: 150 ; Train RMSE = 0.8715 ; Test RMSE = 0.9313\n",
      "Iteration: 160 ; Train RMSE = 0.8583 ; Test RMSE = 0.9276\n",
      "Iteration: 170 ; Train RMSE = 0.8436 ; Test RMSE = 0.9241\n",
      "Iteration: 180 ; Train RMSE = 0.8272 ; Test RMSE = 0.9208\n",
      "Iteration: 190 ; Train RMSE = 0.8092 ; Test RMSE = 0.9180\n",
      "Iteration: 200 ; Train RMSE = 0.7896 ; Test RMSE = 0.9155\n",
      "Iteration: 210 ; Train RMSE = 0.7685 ; Test RMSE = 0.9136\n",
      "Iteration: 220 ; Train RMSE = 0.7462 ; Test RMSE = 0.9123\n",
      "Iteration: 230 ; Train RMSE = 0.7232 ; Test RMSE = 0.9117\n",
      "Iteration: 240 ; Train RMSE = 0.6996 ; Test RMSE = 0.9118\n",
      "Iteration: 250 ; Train RMSE = 0.6758 ; Test RMSE = 0.9124\n",
      "Iteration: 260 ; Train RMSE = 0.6520 ; Test RMSE = 0.9136\n",
      "Iteration: 270 ; Train RMSE = 0.6285 ; Test RMSE = 0.9151\n",
      "Iteration: 280 ; Train RMSE = 0.6054 ; Test RMSE = 0.9170\n",
      "Iteration: 290 ; Train RMSE = 0.5829 ; Test RMSE = 0.9190\n",
      "Iteration: 300 ; Train RMSE = 0.5610 ; Test RMSE = 0.9213\n",
      "K = 120\n",
      "Iteration: 10 ; Train RMSE = 0.9663 ; Test RMSE = 0.9833\n",
      "Iteration: 20 ; Train RMSE = 0.9418 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9311 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9250 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9210 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9181 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9158 ; Test RMSE = 0.9467\n",
      "Iteration: 80 ; Train RMSE = 0.9136 ; Test RMSE = 0.9457\n",
      "Iteration: 90 ; Train RMSE = 0.9114 ; Test RMSE = 0.9448\n",
      "Iteration: 100 ; Train RMSE = 0.9087 ; Test RMSE = 0.9438\n",
      "Iteration: 110 ; Train RMSE = 0.9052 ; Test RMSE = 0.9425\n",
      "Iteration: 120 ; Train RMSE = 0.9003 ; Test RMSE = 0.9408\n",
      "Iteration: 130 ; Train RMSE = 0.8934 ; Test RMSE = 0.9383\n",
      "Iteration: 140 ; Train RMSE = 0.8843 ; Test RMSE = 0.9350\n",
      "Iteration: 150 ; Train RMSE = 0.8729 ; Test RMSE = 0.9313\n",
      "Iteration: 160 ; Train RMSE = 0.8599 ; Test RMSE = 0.9275\n",
      "Iteration: 170 ; Train RMSE = 0.8455 ; Test RMSE = 0.9240\n",
      "Iteration: 180 ; Train RMSE = 0.8296 ; Test RMSE = 0.9208\n",
      "Iteration: 190 ; Train RMSE = 0.8123 ; Test RMSE = 0.9179\n",
      "Iteration: 200 ; Train RMSE = 0.7933 ; Test RMSE = 0.9154\n",
      "Iteration: 210 ; Train RMSE = 0.7728 ; Test RMSE = 0.9134\n",
      "Iteration: 220 ; Train RMSE = 0.7510 ; Test RMSE = 0.9120\n",
      "Iteration: 230 ; Train RMSE = 0.7281 ; Test RMSE = 0.9111\n",
      "Iteration: 240 ; Train RMSE = 0.7045 ; Test RMSE = 0.9108\n",
      "Iteration: 250 ; Train RMSE = 0.6805 ; Test RMSE = 0.9111\n",
      "Iteration: 260 ; Train RMSE = 0.6565 ; Test RMSE = 0.9119\n",
      "Iteration: 270 ; Train RMSE = 0.6326 ; Test RMSE = 0.9131\n",
      "Iteration: 280 ; Train RMSE = 0.6092 ; Test RMSE = 0.9146\n",
      "Iteration: 290 ; Train RMSE = 0.5863 ; Test RMSE = 0.9164\n",
      "Iteration: 300 ; Train RMSE = 0.5642 ; Test RMSE = 0.9183\n",
      "K = 130\n",
      "Iteration: 10 ; Train RMSE = 0.9663 ; Test RMSE = 0.9833\n",
      "Iteration: 20 ; Train RMSE = 0.9419 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9312 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9250 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9211 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9182 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9159 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9139 ; Test RMSE = 0.9458\n",
      "Iteration: 90 ; Train RMSE = 0.9118 ; Test RMSE = 0.9449\n",
      "Iteration: 100 ; Train RMSE = 0.9093 ; Test RMSE = 0.9440\n",
      "Iteration: 110 ; Train RMSE = 0.9061 ; Test RMSE = 0.9429\n",
      "Iteration: 120 ; Train RMSE = 0.9016 ; Test RMSE = 0.9414\n",
      "Iteration: 130 ; Train RMSE = 0.8953 ; Test RMSE = 0.9391\n",
      "Iteration: 140 ; Train RMSE = 0.8867 ; Test RMSE = 0.9360\n",
      "Iteration: 150 ; Train RMSE = 0.8758 ; Test RMSE = 0.9323\n",
      "Iteration: 160 ; Train RMSE = 0.8629 ; Test RMSE = 0.9284\n",
      "Iteration: 170 ; Train RMSE = 0.8486 ; Test RMSE = 0.9247\n",
      "Iteration: 180 ; Train RMSE = 0.8330 ; Test RMSE = 0.9213\n",
      "Iteration: 190 ; Train RMSE = 0.8159 ; Test RMSE = 0.9184\n",
      "Iteration: 200 ; Train RMSE = 0.7973 ; Test RMSE = 0.9159\n",
      "Iteration: 210 ; Train RMSE = 0.7771 ; Test RMSE = 0.9140\n",
      "Iteration: 220 ; Train RMSE = 0.7556 ; Test RMSE = 0.9126\n",
      "Iteration: 230 ; Train RMSE = 0.7331 ; Test RMSE = 0.9118\n",
      "Iteration: 240 ; Train RMSE = 0.7097 ; Test RMSE = 0.9116\n",
      "Iteration: 250 ; Train RMSE = 0.6858 ; Test RMSE = 0.9120\n",
      "Iteration: 260 ; Train RMSE = 0.6617 ; Test RMSE = 0.9128\n",
      "Iteration: 270 ; Train RMSE = 0.6378 ; Test RMSE = 0.9142\n",
      "Iteration: 280 ; Train RMSE = 0.6141 ; Test RMSE = 0.9158\n",
      "Iteration: 290 ; Train RMSE = 0.5909 ; Test RMSE = 0.9177\n",
      "Iteration: 300 ; Train RMSE = 0.5684 ; Test RMSE = 0.9198\n",
      "K = 140\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9419 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9312 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9251 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9211 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9183 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9160 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9140 ; Test RMSE = 0.9458\n",
      "Iteration: 90 ; Train RMSE = 0.9120 ; Test RMSE = 0.9449\n",
      "Iteration: 100 ; Train RMSE = 0.9097 ; Test RMSE = 0.9440\n",
      "Iteration: 110 ; Train RMSE = 0.9066 ; Test RMSE = 0.9428\n",
      "Iteration: 120 ; Train RMSE = 0.9023 ; Test RMSE = 0.9412\n",
      "Iteration: 130 ; Train RMSE = 0.8963 ; Test RMSE = 0.9389\n",
      "Iteration: 140 ; Train RMSE = 0.8881 ; Test RMSE = 0.9359\n",
      "Iteration: 150 ; Train RMSE = 0.8777 ; Test RMSE = 0.9322\n",
      "Iteration: 160 ; Train RMSE = 0.8655 ; Test RMSE = 0.9285\n",
      "Iteration: 170 ; Train RMSE = 0.8517 ; Test RMSE = 0.9248\n",
      "Iteration: 180 ; Train RMSE = 0.8364 ; Test RMSE = 0.9215\n",
      "Iteration: 190 ; Train RMSE = 0.8196 ; Test RMSE = 0.9185\n",
      "Iteration: 200 ; Train RMSE = 0.8012 ; Test RMSE = 0.9159\n",
      "Iteration: 210 ; Train RMSE = 0.7812 ; Test RMSE = 0.9137\n",
      "Iteration: 220 ; Train RMSE = 0.7599 ; Test RMSE = 0.9121\n",
      "Iteration: 230 ; Train RMSE = 0.7375 ; Test RMSE = 0.9112\n",
      "Iteration: 240 ; Train RMSE = 0.7141 ; Test RMSE = 0.9107\n",
      "Iteration: 250 ; Train RMSE = 0.6903 ; Test RMSE = 0.9109\n",
      "Iteration: 260 ; Train RMSE = 0.6661 ; Test RMSE = 0.9116\n",
      "Iteration: 270 ; Train RMSE = 0.6420 ; Test RMSE = 0.9127\n",
      "Iteration: 280 ; Train RMSE = 0.6181 ; Test RMSE = 0.9141\n",
      "Iteration: 290 ; Train RMSE = 0.5947 ; Test RMSE = 0.9159\n",
      "Iteration: 300 ; Train RMSE = 0.5720 ; Test RMSE = 0.9178\n",
      "K = 150\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9419 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9312 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9251 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9212 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9184 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9161 ; Test RMSE = 0.9467\n",
      "Iteration: 80 ; Train RMSE = 0.9142 ; Test RMSE = 0.9457\n",
      "Iteration: 90 ; Train RMSE = 0.9122 ; Test RMSE = 0.9449\n",
      "Iteration: 100 ; Train RMSE = 0.9098 ; Test RMSE = 0.9439\n",
      "Iteration: 110 ; Train RMSE = 0.9067 ; Test RMSE = 0.9427\n",
      "Iteration: 120 ; Train RMSE = 0.9025 ; Test RMSE = 0.9411\n",
      "Iteration: 130 ; Train RMSE = 0.8964 ; Test RMSE = 0.9387\n",
      "Iteration: 140 ; Train RMSE = 0.8883 ; Test RMSE = 0.9355\n",
      "Iteration: 150 ; Train RMSE = 0.8782 ; Test RMSE = 0.9319\n",
      "Iteration: 160 ; Train RMSE = 0.8664 ; Test RMSE = 0.9281\n",
      "Iteration: 170 ; Train RMSE = 0.8533 ; Test RMSE = 0.9244\n",
      "Iteration: 180 ; Train RMSE = 0.8388 ; Test RMSE = 0.9210\n",
      "Iteration: 190 ; Train RMSE = 0.8228 ; Test RMSE = 0.9180\n",
      "Iteration: 200 ; Train RMSE = 0.8052 ; Test RMSE = 0.9152\n",
      "Iteration: 210 ; Train RMSE = 0.7861 ; Test RMSE = 0.9128\n",
      "Iteration: 220 ; Train RMSE = 0.7654 ; Test RMSE = 0.9109\n",
      "Iteration: 230 ; Train RMSE = 0.7435 ; Test RMSE = 0.9096\n",
      "Iteration: 240 ; Train RMSE = 0.7205 ; Test RMSE = 0.9089\n",
      "Iteration: 250 ; Train RMSE = 0.6969 ; Test RMSE = 0.9087\n",
      "Iteration: 260 ; Train RMSE = 0.6729 ; Test RMSE = 0.9091\n",
      "Iteration: 270 ; Train RMSE = 0.6489 ; Test RMSE = 0.9099\n",
      "Iteration: 280 ; Train RMSE = 0.6250 ; Test RMSE = 0.9111\n",
      "Iteration: 290 ; Train RMSE = 0.6015 ; Test RMSE = 0.9126\n",
      "Iteration: 300 ; Train RMSE = 0.5785 ; Test RMSE = 0.9144\n",
      "K = 160\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9419 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9252 ; Test RMSE = 0.9524\n",
      "Iteration: 50 ; Train RMSE = 0.9212 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9184 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9163 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9143 ; Test RMSE = 0.9458\n",
      "Iteration: 90 ; Train RMSE = 0.9125 ; Test RMSE = 0.9450\n",
      "Iteration: 100 ; Train RMSE = 0.9103 ; Test RMSE = 0.9442\n",
      "Iteration: 110 ; Train RMSE = 0.9075 ; Test RMSE = 0.9431\n",
      "Iteration: 120 ; Train RMSE = 0.9037 ; Test RMSE = 0.9416\n",
      "Iteration: 130 ; Train RMSE = 0.8982 ; Test RMSE = 0.9395\n",
      "Iteration: 140 ; Train RMSE = 0.8906 ; Test RMSE = 0.9367\n",
      "Iteration: 150 ; Train RMSE = 0.8809 ; Test RMSE = 0.9331\n",
      "Iteration: 160 ; Train RMSE = 0.8692 ; Test RMSE = 0.9293\n",
      "Iteration: 170 ; Train RMSE = 0.8561 ; Test RMSE = 0.9256\n",
      "Iteration: 180 ; Train RMSE = 0.8417 ; Test RMSE = 0.9222\n",
      "Iteration: 190 ; Train RMSE = 0.8258 ; Test RMSE = 0.9192\n",
      "Iteration: 200 ; Train RMSE = 0.8083 ; Test RMSE = 0.9165\n",
      "Iteration: 210 ; Train RMSE = 0.7892 ; Test RMSE = 0.9142\n",
      "Iteration: 220 ; Train RMSE = 0.7686 ; Test RMSE = 0.9124\n",
      "Iteration: 230 ; Train RMSE = 0.7467 ; Test RMSE = 0.9112\n",
      "Iteration: 240 ; Train RMSE = 0.7238 ; Test RMSE = 0.9105\n",
      "Iteration: 250 ; Train RMSE = 0.7002 ; Test RMSE = 0.9104\n",
      "Iteration: 260 ; Train RMSE = 0.6762 ; Test RMSE = 0.9109\n",
      "Iteration: 270 ; Train RMSE = 0.6520 ; Test RMSE = 0.9119\n",
      "Iteration: 280 ; Train RMSE = 0.6280 ; Test RMSE = 0.9132\n",
      "Iteration: 290 ; Train RMSE = 0.6044 ; Test RMSE = 0.9149\n",
      "Iteration: 300 ; Train RMSE = 0.5812 ; Test RMSE = 0.9167\n",
      "K = 170\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9419 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9252 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9213 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9185 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9163 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9145 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9127 ; Test RMSE = 0.9451\n",
      "Iteration: 100 ; Train RMSE = 0.9106 ; Test RMSE = 0.9443\n",
      "Iteration: 110 ; Train RMSE = 0.9080 ; Test RMSE = 0.9433\n",
      "Iteration: 120 ; Train RMSE = 0.9045 ; Test RMSE = 0.9420\n",
      "Iteration: 130 ; Train RMSE = 0.8994 ; Test RMSE = 0.9401\n",
      "Iteration: 140 ; Train RMSE = 0.8923 ; Test RMSE = 0.9373\n",
      "Iteration: 150 ; Train RMSE = 0.8829 ; Test RMSE = 0.9339\n",
      "Iteration: 160 ; Train RMSE = 0.8715 ; Test RMSE = 0.9301\n",
      "Iteration: 170 ; Train RMSE = 0.8584 ; Test RMSE = 0.9264\n",
      "Iteration: 180 ; Train RMSE = 0.8440 ; Test RMSE = 0.9229\n",
      "Iteration: 190 ; Train RMSE = 0.8281 ; Test RMSE = 0.9197\n",
      "Iteration: 200 ; Train RMSE = 0.8106 ; Test RMSE = 0.9169\n",
      "Iteration: 210 ; Train RMSE = 0.7916 ; Test RMSE = 0.9145\n",
      "Iteration: 220 ; Train RMSE = 0.7711 ; Test RMSE = 0.9126\n",
      "Iteration: 230 ; Train RMSE = 0.7493 ; Test RMSE = 0.9112\n",
      "Iteration: 240 ; Train RMSE = 0.7265 ; Test RMSE = 0.9105\n",
      "Iteration: 250 ; Train RMSE = 0.7030 ; Test RMSE = 0.9103\n",
      "Iteration: 260 ; Train RMSE = 0.6790 ; Test RMSE = 0.9107\n",
      "Iteration: 270 ; Train RMSE = 0.6549 ; Test RMSE = 0.9116\n",
      "Iteration: 280 ; Train RMSE = 0.6309 ; Test RMSE = 0.9129\n",
      "Iteration: 290 ; Train RMSE = 0.6072 ; Test RMSE = 0.9144\n",
      "Iteration: 300 ; Train RMSE = 0.5840 ; Test RMSE = 0.9162\n",
      "K = 180\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9833\n",
      "Iteration: 20 ; Train RMSE = 0.9419 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9252 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9213 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9185 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9164 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9145 ; Test RMSE = 0.9458\n",
      "Iteration: 90 ; Train RMSE = 0.9127 ; Test RMSE = 0.9450\n",
      "Iteration: 100 ; Train RMSE = 0.9107 ; Test RMSE = 0.9442\n",
      "Iteration: 110 ; Train RMSE = 0.9081 ; Test RMSE = 0.9432\n",
      "Iteration: 120 ; Train RMSE = 0.9045 ; Test RMSE = 0.9418\n",
      "Iteration: 130 ; Train RMSE = 0.8995 ; Test RMSE = 0.9399\n",
      "Iteration: 140 ; Train RMSE = 0.8924 ; Test RMSE = 0.9371\n",
      "Iteration: 150 ; Train RMSE = 0.8832 ; Test RMSE = 0.9337\n",
      "Iteration: 160 ; Train RMSE = 0.8722 ; Test RMSE = 0.9300\n",
      "Iteration: 170 ; Train RMSE = 0.8596 ; Test RMSE = 0.9264\n",
      "Iteration: 180 ; Train RMSE = 0.8457 ; Test RMSE = 0.9229\n",
      "Iteration: 190 ; Train RMSE = 0.8303 ; Test RMSE = 0.9198\n",
      "Iteration: 200 ; Train RMSE = 0.8133 ; Test RMSE = 0.9168\n",
      "Iteration: 210 ; Train RMSE = 0.7946 ; Test RMSE = 0.9143\n",
      "Iteration: 220 ; Train RMSE = 0.7743 ; Test RMSE = 0.9122\n",
      "Iteration: 230 ; Train RMSE = 0.7527 ; Test RMSE = 0.9106\n",
      "Iteration: 240 ; Train RMSE = 0.7300 ; Test RMSE = 0.9097\n",
      "Iteration: 250 ; Train RMSE = 0.7065 ; Test RMSE = 0.9093\n",
      "Iteration: 260 ; Train RMSE = 0.6826 ; Test RMSE = 0.9095\n",
      "Iteration: 270 ; Train RMSE = 0.6585 ; Test RMSE = 0.9102\n",
      "Iteration: 280 ; Train RMSE = 0.6344 ; Test RMSE = 0.9114\n",
      "Iteration: 290 ; Train RMSE = 0.6106 ; Test RMSE = 0.9128\n",
      "Iteration: 300 ; Train RMSE = 0.5873 ; Test RMSE = 0.9145\n",
      "K = 190\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9253 ; Test RMSE = 0.9524\n",
      "Iteration: 50 ; Train RMSE = 0.9214 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9186 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9165 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9147 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9130 ; Test RMSE = 0.9452\n",
      "Iteration: 100 ; Train RMSE = 0.9111 ; Test RMSE = 0.9444\n",
      "Iteration: 110 ; Train RMSE = 0.9088 ; Test RMSE = 0.9436\n",
      "Iteration: 120 ; Train RMSE = 0.9057 ; Test RMSE = 0.9425\n",
      "Iteration: 130 ; Train RMSE = 0.9012 ; Test RMSE = 0.9409\n",
      "Iteration: 140 ; Train RMSE = 0.8949 ; Test RMSE = 0.9386\n",
      "Iteration: 150 ; Train RMSE = 0.8863 ; Test RMSE = 0.9355\n",
      "Iteration: 160 ; Train RMSE = 0.8754 ; Test RMSE = 0.9318\n",
      "Iteration: 170 ; Train RMSE = 0.8626 ; Test RMSE = 0.9278\n",
      "Iteration: 180 ; Train RMSE = 0.8484 ; Test RMSE = 0.9241\n",
      "Iteration: 190 ; Train RMSE = 0.8327 ; Test RMSE = 0.9207\n",
      "Iteration: 200 ; Train RMSE = 0.8155 ; Test RMSE = 0.9177\n",
      "Iteration: 210 ; Train RMSE = 0.7967 ; Test RMSE = 0.9150\n",
      "Iteration: 220 ; Train RMSE = 0.7764 ; Test RMSE = 0.9130\n",
      "Iteration: 230 ; Train RMSE = 0.7549 ; Test RMSE = 0.9114\n",
      "Iteration: 240 ; Train RMSE = 0.7322 ; Test RMSE = 0.9105\n",
      "Iteration: 250 ; Train RMSE = 0.7088 ; Test RMSE = 0.9101\n",
      "Iteration: 260 ; Train RMSE = 0.6849 ; Test RMSE = 0.9103\n",
      "Iteration: 270 ; Train RMSE = 0.6608 ; Test RMSE = 0.9110\n",
      "Iteration: 280 ; Train RMSE = 0.6368 ; Test RMSE = 0.9121\n",
      "Iteration: 290 ; Train RMSE = 0.6130 ; Test RMSE = 0.9135\n",
      "Iteration: 300 ; Train RMSE = 0.5897 ; Test RMSE = 0.9152\n",
      "K = 200\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9253 ; Test RMSE = 0.9524\n",
      "Iteration: 50 ; Train RMSE = 0.9214 ; Test RMSE = 0.9498\n",
      "Iteration: 60 ; Train RMSE = 0.9186 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9165 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9147 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9130 ; Test RMSE = 0.9451\n",
      "Iteration: 100 ; Train RMSE = 0.9112 ; Test RMSE = 0.9444\n",
      "Iteration: 110 ; Train RMSE = 0.9088 ; Test RMSE = 0.9435\n",
      "Iteration: 120 ; Train RMSE = 0.9057 ; Test RMSE = 0.9423\n",
      "Iteration: 130 ; Train RMSE = 0.9011 ; Test RMSE = 0.9406\n",
      "Iteration: 140 ; Train RMSE = 0.8947 ; Test RMSE = 0.9381\n",
      "Iteration: 150 ; Train RMSE = 0.8862 ; Test RMSE = 0.9349\n",
      "Iteration: 160 ; Train RMSE = 0.8756 ; Test RMSE = 0.9312\n",
      "Iteration: 170 ; Train RMSE = 0.8633 ; Test RMSE = 0.9274\n",
      "Iteration: 180 ; Train RMSE = 0.8497 ; Test RMSE = 0.9239\n",
      "Iteration: 190 ; Train RMSE = 0.8348 ; Test RMSE = 0.9207\n",
      "Iteration: 200 ; Train RMSE = 0.8183 ; Test RMSE = 0.9177\n",
      "Iteration: 210 ; Train RMSE = 0.8001 ; Test RMSE = 0.9151\n",
      "Iteration: 220 ; Train RMSE = 0.7804 ; Test RMSE = 0.9130\n",
      "Iteration: 230 ; Train RMSE = 0.7592 ; Test RMSE = 0.9114\n",
      "Iteration: 240 ; Train RMSE = 0.7368 ; Test RMSE = 0.9103\n",
      "Iteration: 250 ; Train RMSE = 0.7135 ; Test RMSE = 0.9098\n",
      "Iteration: 260 ; Train RMSE = 0.6896 ; Test RMSE = 0.9098\n",
      "Iteration: 270 ; Train RMSE = 0.6654 ; Test RMSE = 0.9104\n",
      "Iteration: 280 ; Train RMSE = 0.6412 ; Test RMSE = 0.9114\n",
      "Iteration: 290 ; Train RMSE = 0.6173 ; Test RMSE = 0.9128\n",
      "Iteration: 300 ; Train RMSE = 0.5937 ; Test RMSE = 0.9145\n",
      "K = 210\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9253 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9214 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9187 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9166 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9149 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9132 ; Test RMSE = 0.9452\n",
      "Iteration: 100 ; Train RMSE = 0.9115 ; Test RMSE = 0.9445\n",
      "Iteration: 110 ; Train RMSE = 0.9093 ; Test RMSE = 0.9437\n",
      "Iteration: 120 ; Train RMSE = 0.9064 ; Test RMSE = 0.9427\n",
      "Iteration: 130 ; Train RMSE = 0.9023 ; Test RMSE = 0.9411\n",
      "Iteration: 140 ; Train RMSE = 0.8965 ; Test RMSE = 0.9390\n",
      "Iteration: 150 ; Train RMSE = 0.8884 ; Test RMSE = 0.9360\n",
      "Iteration: 160 ; Train RMSE = 0.8781 ; Test RMSE = 0.9324\n",
      "Iteration: 170 ; Train RMSE = 0.8659 ; Test RMSE = 0.9285\n",
      "Iteration: 180 ; Train RMSE = 0.8523 ; Test RMSE = 0.9248\n",
      "Iteration: 190 ; Train RMSE = 0.8373 ; Test RMSE = 0.9214\n",
      "Iteration: 200 ; Train RMSE = 0.8209 ; Test RMSE = 0.9183\n",
      "Iteration: 210 ; Train RMSE = 0.8030 ; Test RMSE = 0.9156\n",
      "Iteration: 220 ; Train RMSE = 0.7835 ; Test RMSE = 0.9134\n",
      "Iteration: 230 ; Train RMSE = 0.7626 ; Test RMSE = 0.9116\n",
      "Iteration: 240 ; Train RMSE = 0.7404 ; Test RMSE = 0.9104\n",
      "Iteration: 250 ; Train RMSE = 0.7173 ; Test RMSE = 0.9098\n",
      "Iteration: 260 ; Train RMSE = 0.6936 ; Test RMSE = 0.9098\n",
      "Iteration: 270 ; Train RMSE = 0.6696 ; Test RMSE = 0.9103\n",
      "Iteration: 280 ; Train RMSE = 0.6456 ; Test RMSE = 0.9113\n",
      "Iteration: 290 ; Train RMSE = 0.6217 ; Test RMSE = 0.9126\n",
      "Iteration: 300 ; Train RMSE = 0.5981 ; Test RMSE = 0.9142\n",
      "K = 220\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9313 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9253 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9214 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9187 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9166 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9149 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9133 ; Test RMSE = 0.9452\n",
      "Iteration: 100 ; Train RMSE = 0.9115 ; Test RMSE = 0.9444\n",
      "Iteration: 110 ; Train RMSE = 0.9093 ; Test RMSE = 0.9436\n",
      "Iteration: 120 ; Train RMSE = 0.9064 ; Test RMSE = 0.9424\n",
      "Iteration: 130 ; Train RMSE = 0.9022 ; Test RMSE = 0.9408\n",
      "Iteration: 140 ; Train RMSE = 0.8962 ; Test RMSE = 0.9384\n",
      "Iteration: 150 ; Train RMSE = 0.8882 ; Test RMSE = 0.9354\n",
      "Iteration: 160 ; Train RMSE = 0.8782 ; Test RMSE = 0.9318\n",
      "Iteration: 170 ; Train RMSE = 0.8665 ; Test RMSE = 0.9281\n",
      "Iteration: 180 ; Train RMSE = 0.8535 ; Test RMSE = 0.9247\n",
      "Iteration: 190 ; Train RMSE = 0.8392 ; Test RMSE = 0.9215\n",
      "Iteration: 200 ; Train RMSE = 0.8232 ; Test RMSE = 0.9185\n",
      "Iteration: 210 ; Train RMSE = 0.8056 ; Test RMSE = 0.9158\n",
      "Iteration: 220 ; Train RMSE = 0.7863 ; Test RMSE = 0.9135\n",
      "Iteration: 230 ; Train RMSE = 0.7655 ; Test RMSE = 0.9117\n",
      "Iteration: 240 ; Train RMSE = 0.7433 ; Test RMSE = 0.9104\n",
      "Iteration: 250 ; Train RMSE = 0.7201 ; Test RMSE = 0.9097\n",
      "Iteration: 260 ; Train RMSE = 0.6962 ; Test RMSE = 0.9096\n",
      "Iteration: 270 ; Train RMSE = 0.6718 ; Test RMSE = 0.9100\n",
      "Iteration: 280 ; Train RMSE = 0.6474 ; Test RMSE = 0.9109\n",
      "Iteration: 290 ; Train RMSE = 0.6232 ; Test RMSE = 0.9121\n",
      "Iteration: 300 ; Train RMSE = 0.5993 ; Test RMSE = 0.9136\n",
      "K = 230\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9314 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9253 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9215 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9187 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9167 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9150 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9134 ; Test RMSE = 0.9452\n",
      "Iteration: 100 ; Train RMSE = 0.9117 ; Test RMSE = 0.9445\n",
      "Iteration: 110 ; Train RMSE = 0.9096 ; Test RMSE = 0.9437\n",
      "Iteration: 120 ; Train RMSE = 0.9068 ; Test RMSE = 0.9427\n",
      "Iteration: 130 ; Train RMSE = 0.9029 ; Test RMSE = 0.9412\n",
      "Iteration: 140 ; Train RMSE = 0.8972 ; Test RMSE = 0.9390\n",
      "Iteration: 150 ; Train RMSE = 0.8894 ; Test RMSE = 0.9360\n",
      "Iteration: 160 ; Train RMSE = 0.8794 ; Test RMSE = 0.9323\n",
      "Iteration: 170 ; Train RMSE = 0.8676 ; Test RMSE = 0.9285\n",
      "Iteration: 180 ; Train RMSE = 0.8544 ; Test RMSE = 0.9248\n",
      "Iteration: 190 ; Train RMSE = 0.8398 ; Test RMSE = 0.9215\n",
      "Iteration: 200 ; Train RMSE = 0.8238 ; Test RMSE = 0.9185\n",
      "Iteration: 210 ; Train RMSE = 0.8064 ; Test RMSE = 0.9158\n",
      "Iteration: 220 ; Train RMSE = 0.7874 ; Test RMSE = 0.9136\n",
      "Iteration: 230 ; Train RMSE = 0.7669 ; Test RMSE = 0.9118\n",
      "Iteration: 240 ; Train RMSE = 0.7452 ; Test RMSE = 0.9106\n",
      "Iteration: 250 ; Train RMSE = 0.7224 ; Test RMSE = 0.9099\n",
      "Iteration: 260 ; Train RMSE = 0.6989 ; Test RMSE = 0.9098\n",
      "Iteration: 270 ; Train RMSE = 0.6750 ; Test RMSE = 0.9102\n",
      "Iteration: 280 ; Train RMSE = 0.6508 ; Test RMSE = 0.9110\n",
      "Iteration: 290 ; Train RMSE = 0.6268 ; Test RMSE = 0.9123\n",
      "Iteration: 300 ; Train RMSE = 0.6030 ; Test RMSE = 0.9138\n",
      "K = 240\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9314 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9253 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9215 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9188 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9167 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9150 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9135 ; Test RMSE = 0.9452\n",
      "Iteration: 100 ; Train RMSE = 0.9118 ; Test RMSE = 0.9446\n",
      "Iteration: 110 ; Train RMSE = 0.9098 ; Test RMSE = 0.9438\n",
      "Iteration: 120 ; Train RMSE = 0.9072 ; Test RMSE = 0.9428\n",
      "Iteration: 130 ; Train RMSE = 0.9034 ; Test RMSE = 0.9414\n",
      "Iteration: 140 ; Train RMSE = 0.8981 ; Test RMSE = 0.9393\n",
      "Iteration: 150 ; Train RMSE = 0.8906 ; Test RMSE = 0.9365\n",
      "Iteration: 160 ; Train RMSE = 0.8811 ; Test RMSE = 0.9330\n",
      "Iteration: 170 ; Train RMSE = 0.8697 ; Test RMSE = 0.9292\n",
      "Iteration: 180 ; Train RMSE = 0.8568 ; Test RMSE = 0.9255\n",
      "Iteration: 190 ; Train RMSE = 0.8426 ; Test RMSE = 0.9220\n",
      "Iteration: 200 ; Train RMSE = 0.8268 ; Test RMSE = 0.9188\n",
      "Iteration: 210 ; Train RMSE = 0.8095 ; Test RMSE = 0.9159\n",
      "Iteration: 220 ; Train RMSE = 0.7905 ; Test RMSE = 0.9134\n",
      "Iteration: 230 ; Train RMSE = 0.7700 ; Test RMSE = 0.9114\n",
      "Iteration: 240 ; Train RMSE = 0.7483 ; Test RMSE = 0.9100\n",
      "Iteration: 250 ; Train RMSE = 0.7255 ; Test RMSE = 0.9092\n",
      "Iteration: 260 ; Train RMSE = 0.7021 ; Test RMSE = 0.9089\n",
      "Iteration: 270 ; Train RMSE = 0.6782 ; Test RMSE = 0.9092\n",
      "Iteration: 280 ; Train RMSE = 0.6542 ; Test RMSE = 0.9099\n",
      "Iteration: 290 ; Train RMSE = 0.6302 ; Test RMSE = 0.9110\n",
      "Iteration: 300 ; Train RMSE = 0.6064 ; Test RMSE = 0.9124\n",
      "K = 250\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9314 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9254 ; Test RMSE = 0.9524\n",
      "Iteration: 50 ; Train RMSE = 0.9215 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9188 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9167 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9151 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9135 ; Test RMSE = 0.9452\n",
      "Iteration: 100 ; Train RMSE = 0.9118 ; Test RMSE = 0.9445\n",
      "Iteration: 110 ; Train RMSE = 0.9098 ; Test RMSE = 0.9437\n",
      "Iteration: 120 ; Train RMSE = 0.9071 ; Test RMSE = 0.9427\n",
      "Iteration: 130 ; Train RMSE = 0.9033 ; Test RMSE = 0.9412\n",
      "Iteration: 140 ; Train RMSE = 0.8978 ; Test RMSE = 0.9390\n",
      "Iteration: 150 ; Train RMSE = 0.8902 ; Test RMSE = 0.9361\n",
      "Iteration: 160 ; Train RMSE = 0.8806 ; Test RMSE = 0.9325\n",
      "Iteration: 170 ; Train RMSE = 0.8693 ; Test RMSE = 0.9288\n",
      "Iteration: 180 ; Train RMSE = 0.8567 ; Test RMSE = 0.9253\n",
      "Iteration: 190 ; Train RMSE = 0.8428 ; Test RMSE = 0.9220\n",
      "Iteration: 200 ; Train RMSE = 0.8275 ; Test RMSE = 0.9189\n",
      "Iteration: 210 ; Train RMSE = 0.8105 ; Test RMSE = 0.9161\n",
      "Iteration: 220 ; Train RMSE = 0.7920 ; Test RMSE = 0.9137\n",
      "Iteration: 230 ; Train RMSE = 0.7718 ; Test RMSE = 0.9117\n",
      "Iteration: 240 ; Train RMSE = 0.7503 ; Test RMSE = 0.9103\n",
      "Iteration: 250 ; Train RMSE = 0.7277 ; Test RMSE = 0.9094\n",
      "Iteration: 260 ; Train RMSE = 0.7043 ; Test RMSE = 0.9090\n",
      "Iteration: 270 ; Train RMSE = 0.6804 ; Test RMSE = 0.9092\n",
      "Iteration: 280 ; Train RMSE = 0.6563 ; Test RMSE = 0.9099\n",
      "Iteration: 290 ; Train RMSE = 0.6323 ; Test RMSE = 0.9110\n",
      "Iteration: 300 ; Train RMSE = 0.6086 ; Test RMSE = 0.9125\n",
      "K = 260\n",
      "Iteration: 10 ; Train RMSE = 0.9664 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9420 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9314 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9254 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9215 ; Test RMSE = 0.9498\n",
      "Iteration: 60 ; Train RMSE = 0.9188 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9168 ; Test RMSE = 0.9468\n",
      "Iteration: 80 ; Train RMSE = 0.9151 ; Test RMSE = 0.9459\n",
      "Iteration: 90 ; Train RMSE = 0.9136 ; Test RMSE = 0.9452\n",
      "Iteration: 100 ; Train RMSE = 0.9121 ; Test RMSE = 0.9446\n",
      "Iteration: 110 ; Train RMSE = 0.9102 ; Test RMSE = 0.9439\n",
      "Iteration: 120 ; Train RMSE = 0.9078 ; Test RMSE = 0.9430\n",
      "Iteration: 130 ; Train RMSE = 0.9044 ; Test RMSE = 0.9417\n",
      "Iteration: 140 ; Train RMSE = 0.8995 ; Test RMSE = 0.9398\n",
      "Iteration: 150 ; Train RMSE = 0.8925 ; Test RMSE = 0.9372\n",
      "Iteration: 160 ; Train RMSE = 0.8834 ; Test RMSE = 0.9338\n",
      "Iteration: 170 ; Train RMSE = 0.8724 ; Test RMSE = 0.9301\n",
      "Iteration: 180 ; Train RMSE = 0.8597 ; Test RMSE = 0.9263\n",
      "Iteration: 190 ; Train RMSE = 0.8457 ; Test RMSE = 0.9228\n",
      "Iteration: 200 ; Train RMSE = 0.8302 ; Test RMSE = 0.9195\n",
      "Iteration: 210 ; Train RMSE = 0.8130 ; Test RMSE = 0.9165\n",
      "Iteration: 220 ; Train RMSE = 0.7943 ; Test RMSE = 0.9139\n",
      "Iteration: 230 ; Train RMSE = 0.7740 ; Test RMSE = 0.9118\n",
      "Iteration: 240 ; Train RMSE = 0.7525 ; Test RMSE = 0.9102\n",
      "Iteration: 250 ; Train RMSE = 0.7299 ; Test RMSE = 0.9092\n",
      "Iteration: 260 ; Train RMSE = 0.7065 ; Test RMSE = 0.9089\n",
      "Iteration: 270 ; Train RMSE = 0.6827 ; Test RMSE = 0.9091\n",
      "Iteration: 280 ; Train RMSE = 0.6586 ; Test RMSE = 0.9099\n",
      "Iteration: 290 ; Train RMSE = 0.6346 ; Test RMSE = 0.9110\n",
      "Iteration: 300 ; Train RMSE = 0.6107 ; Test RMSE = 0.9125\n"
     ]
    }
   ],
   "source": [
    "# 최적의 K값 찾기\n",
    "results = []\n",
    "index = []\n",
    "for K in range(50, 261, 10):\n",
    "    print('K =', K)\n",
    "    R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "    mf = NEW_MF(R_temp, K=K, alpha=0.001, beta=0.02, iterations=300, verbose=True)\n",
    "    test_set = mf.set_test(ratings_test)\n",
    "    result = mf.test()\n",
    "    index.append(K)\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "WA9Eh8pT-Lq2",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1728897651314,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "WA9Eh8pT-Lq2"
   },
   "outputs": [],
   "source": [
    "# 최적의 iterations 값 찾기\n",
    "summary = []\n",
    "for i in range(len(results)):\n",
    "    RMSE = []\n",
    "    for result in results[i]:\n",
    "        RMSE.append(result[2])\n",
    "    min = np.min(RMSE)\n",
    "    j = RMSE.index(min)\n",
    "    summary.append([index[i], j+1, RMSE[j]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sNIj74lZP9JS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1728899608098,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "sNIj74lZP9JS",
    "outputId": "c5293399-7fec-4f07-9f4c-66f42772cc0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[50, 204, np.float64(0.9180944414552399)],\n",
       " [60, 210, np.float64(0.9174219435318853)],\n",
       " [70, 217, np.float64(0.9149633275138546)],\n",
       " [80, 221, np.float64(0.9143756965888005)],\n",
       " [90, 228, np.float64(0.911954869553031)],\n",
       " [100, 233, np.float64(0.9125110893087457)],\n",
       " [110, 234, np.float64(0.9116910053872911)],\n",
       " [120, 240, np.float64(0.9108017724210864)],\n",
       " [130, 238, np.float64(0.9115742157289871)],\n",
       " [140, 241, np.float64(0.9107331372844174)],\n",
       " [150, 247, np.float64(0.9086859139777731)],\n",
       " [160, 247, np.float64(0.9103936946677585)],\n",
       " [170, 247, np.float64(0.9102937799243129)],\n",
       " [180, 252, np.float64(0.9093328484444416)],\n",
       " [190, 251, np.float64(0.9101112648124442)],\n",
       " [200, 254, np.float64(0.9097340694840883)],\n",
       " [210, 256, np.float64(0.9097366006714546)],\n",
       " [220, 256, np.float64(0.9095693922921099)],\n",
       " [230, 257, np.float64(0.9097444292617776)],\n",
       " [240, 260, np.float64(0.9089042840211536)],\n",
       " [250, 261, np.float64(0.9090273015736764)],\n",
       " [260, 261, np.float64(0.9089027840737741)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "VWTq3bH2Zsmb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1728897652756,
     "user": {
      "displayName": "옥철영",
      "userId": "13462808953739637244"
     },
     "user_tz": -540
    },
    "id": "VWTq3bH2Zsmb",
    "outputId": "46174431-2d2f-4a00-bec9-7a298922c118"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(index, [x[2] for x in summary])\n",
    "plt.ylim(0.89, 0.94)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai_recmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
